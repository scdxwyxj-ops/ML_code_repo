{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c898de6",
   "metadata": {},
   "source": [
    "# Q3: How Robust Credit Risk Models are Over Time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439e68c9",
   "metadata": {},
   "source": [
    "This script compares Naive Bayes, Support Vector Machines, Decision Trees, K-Nearest Neighbours, and a Binary Classifier Neural Network in their performance in credit risk prediction when trained and tested data differ in economic periods. The dataset used is that of https://www.kaggle.com/datasets/wordsforthewise/lending-club/data, where the economic periods detailed are between 2007 to 2018. The usable data is split in half to form two periods, periods 1 and 2. All models will be trained on period 1 and tested on period 2. The results of each model are then compared to analyse temporal stability. The classification models were developed to determine whether a candidate would have a low or high credit risk.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616331cf",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4505fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Add project root to path\n",
    "PROJECT_ROOT = Path().resolve().parent\n",
    "sys.path.append(str(PROJECT_ROOT))\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "Q3_DATA_PATH = Path(\"..\") / \"assets\" / \"q3_data\"\n",
    "Q3_DATA_CHUNKS_PATH = Q3_DATA_PATH / \"yearly_samples\"\n",
    "\n",
    "from data_processings.datasets import LendingClubDataset\n",
    "from models.neural import BinaryClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1539d21",
   "metadata": {},
   "source": [
    "## Pre-Processing of Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533444e2",
   "metadata": {},
   "source": [
    "**Building Yearly Samples**\n",
    "\n",
    "The Lending Club Dataset contains millions of samples, which can be very computationally expensive. Due to this, the dataset is iterated through chunks. Then, yearly samples are taken and stored in pickle files. Samples per year are constrained to support memory and time efficiency. \n",
    "\n",
    "*Note: Although the data spans from 2007 to 2018, after filtering through features and removing incomplete data (as seen in datasets.py and feature_engineering.py) Usable data spans from 2012 to 2018. Due to this, data from 2012 to 2015 and 2016 to 2018 are denoted as periods 1 and 2, respectively. Feature engineering is included in build_yearly_samples().*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c2c59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 5000\n",
    "samples_per_year = 5000\n",
    "issue_date_column = 'issue_d'\n",
    "dataloader = LendingClubDataset()\n",
    "dataloader.build_yearly_samples(chunk_size, samples_per_year, Q3_DATA_CHUNKS_PATH, issue_date_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ec4534",
   "metadata": {},
   "source": [
    "**Yearly DataFrames**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9121f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_df = {}\n",
    "start_year = 2012\n",
    "end_year = 2018\n",
    "\n",
    "for i in range(end_year - start_year + 1):\n",
    "    path = os.path.join(Q3_DATA_CHUNKS_PATH, f\"lending_club_{start_year+i}.pkl\")\n",
    "\n",
    "    df = pd.read_pickle(path)\n",
    "\n",
    "    key = f\"{start_year+i}\"\n",
    "\n",
    "    yearly_df[key] = df\n",
    "\n",
    "    print(f\"{key}: {len(df)} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b8141b",
   "metadata": {},
   "source": [
    "Feature Type Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acda249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary Mapping for Binary Categorical Features \n",
    "for year, df in yearly_df.items():\n",
    "\n",
    "    # Binary Mapping for Binary Categorical Features\n",
    "    df = df.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x) # Remove leading and trailing spaces\n",
    "    df['loan_status'] = df['loan_status'].map({'Fully Paid': 0, 'Charged Off': 1}) # Where Fully Paid -> Low Risk and Charged Off -> High Risk\n",
    "    df['application_type'] = df['application_type'].map({'Individual': 0, 'Joint App': 1})\n",
    "    df['term'] = df['term'].map({'36 months': 0, '60 months': 1})\n",
    "\n",
    "    # One Hot Encoding for Non-Binary Categorical Features \n",
    "    categorical_features = [\"purpose\", \"home_ownership\", \"emp_length\", \"verification_status\"]\n",
    "    df = pd.get_dummies(df, columns=categorical_features, drop_first=True, dtype=int)\n",
    "\n",
    "    yearly_df[key] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f45659f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify Types\n",
    "for col, dtype in yearly_df['2015'].dtypes.items():\n",
    "    print(f\"{col}: {dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fa83f9",
   "metadata": {},
   "source": [
    "Train-Test Split Based on Economic Periods: Period 1 (Train) and Period (Test)\n",
    "\n",
    "where: Period 1 (2007-2012) and Period 2 (2013-2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3a8d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_indicator_col = 'issue_year'\n",
    "target_col = 'loan_status'\n",
    "cut_off_year = 2015 \n",
    "train_dfs = []\n",
    "test_dfs = []\n",
    "\n",
    "for year, df in yearly_df.items():\n",
    "    if year <= cut_off_year:\n",
    "        train_dfs.append(df)\n",
    "    else:\n",
    "        test_dfs.append(df)\n",
    "\n",
    "train_df = pd.concat(train_dfs, ignore_index=True)\n",
    "test_df = pd.concat(test_dfs, ignore_index=True)\n",
    "\n",
    "X_train = train_df.drop(columns=[target_col])\n",
    "y_train = train_df[target_col]\n",
    "X_test = test_df.drop(columns=[target_col])\n",
    "y_test = test_df[target_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae59d10",
   "metadata": {},
   "source": [
    "Scaling with MinMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699a293f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MinMax_scaler = MinMaxScaler()\n",
    "X_train = MinMax_scaler.fit_transform(X_train)\n",
    "X_test = MinMax_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740bfe3c",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0c2abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_mapping = {0: 'Low Risk',\n",
    "                 1: 'High Risk'}\n",
    "\n",
    "def dict_to_json(data : dict, folder_path: str, file_name: str):\n",
    "    file_name = f\"{file_name}.json\"\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "    with open(file_path, \"w\") as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "\n",
    "    print(f\"JSON file is saved to {file_path}!\")\n",
    "\n",
    "def conmat_to_png(conmat, class_mapping: dict, folder_path: str, file_name: str, model_name: str):\n",
    "\n",
    "    file_name = f\"{file_name}.png\"\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "    class_labels = list(class_mapping.values())\n",
    "    \n",
    "    fig = plt.figure(figsize=(15, 10))\n",
    "    axis = sns.heatmap(conmat, annot=True, fmt='0.2f', cbar=True, xticklabels=class_labels, yticklabels=class_labels)\n",
    "    \n",
    "    axis.set_ylabel(\"True Values\")\n",
    "\n",
    "    axis.set_xlabel(\"Predicted Values\")\n",
    "\n",
    "    title = f\"Normalized Confusion Matrix for {model_name}\"\n",
    "\n",
    "    axis.set_title(\"Normalized Confusion Matrix\")\n",
    "\n",
    "    fig.savefig(file_path)\n",
    "\n",
    "    print(f\"PNG file is saved to {file_path}!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6539a43d",
   "metadata": {},
   "source": [
    "**Model 1: Naive Bayes**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f48abc",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9517fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "GNB = GaussianNB()\n",
    "GNB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e6cb7d",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc362e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "GNB_preds = GNB.predict(X_test)\n",
    "GNB_summary = classification_report(y_true=y_test, y_pred=GNB_preds, labels=list(class_mapping.keys()), target_names=list(class_mapping.values()), output_dict=True)\n",
    "\n",
    "print(f\"Naive Bayes Accuracy: {GNB_summary['accuracy']}\")\n",
    "\n",
    "GNB_file_name = \"gnb_performance\"\n",
    "dict_to_json(GNB_summary, Q3_DATA_PATH, GNB_file_name)\n",
    "\n",
    "GNB_conmat = confusion_matrix(y_test, GNB_preds, normalize='true')\n",
    "\n",
    "GNB_conmat_name = \"gnb_confusion_matrix\"\n",
    "GNB_model_name = \"Naive Bayes\"\n",
    "conmat_to_png(GNB_conmat, class_mapping, Q3_DATA_PATH, GNB_conmat_name, GNB_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcdcadd",
   "metadata": {},
   "source": [
    "**Model 2: Support Vector Machine**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf86e77f",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b51ca9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "C_vals = [0.01, 0.1, 1.0, 10.0]\n",
    "best_accuracy = 0\n",
    "best_SVM = SVC(C=1)\n",
    "best_C = 0\n",
    "SVM_accuracies = []\n",
    "\n",
    "for i in range(len(C_vals)):\n",
    "    SVM_candidate = SVC(kernel='linear', C=C_vals[i], random_state=10)\n",
    "\n",
    "    print(f\"Training SVM with C Value of {C_vals[i]}\")\n",
    "    SVM_candidate.fit(X_train, y_train)\n",
    "\n",
    "    SVM_candidate_preds = SVM_candidate.predict(X_test)\n",
    "\n",
    "    SVM_candidate_acc = round(accuracy_score(y_test, SVM_candidate_preds), 2)\n",
    "    SVM_accuracies.append(SVM_candidate_acc)\n",
    "\n",
    "    if SVM_candidate_acc > best_accuracy:\n",
    "        best_SVM = SVM_candidate\n",
    "        best_C = C_vals[i]\n",
    "        best_accuracy = SVM_candidate_acc\n",
    "    \n",
    "    print(f\"SVM with C Value of {C_vals[i]} was tested and had an accuracy of {SVM_candidate_acc}!\")\n",
    "\n",
    "SVM = best_SVM\n",
    "\n",
    "print(f\"Best C Value: {best_C}\")\n",
    "print(f\"Accuracy: {best_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e868b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_explore_dict = {\n",
    "    'C': C_vals,\n",
    "    'accuracies': SVM_accuracies\n",
    "}\n",
    "\n",
    "SVM_exp_file_name = \"svm_exploration\"\n",
    "dict_to_json(SVM_explore_dict, Q3_DATA_PATH, SVM_exp_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69e528c",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e8efa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_preds = SVM.predict(X_test)\n",
    "SVM_summary = classification_report(y_true=y_test, y_pred=SVM_preds, labels=list(class_mapping.keys()), target_names=list(class_mapping.values()), output_dict=True)\n",
    "print(f\"Support Vector Machine Accuracy: {best_accuracy}\")\n",
    "\n",
    "SVM_file_name = \"svm_performance\"\n",
    "dict_to_json(SVM_summary, Q3_DATA_PATH, SVM_file_name)\n",
    "\n",
    "SVM_conmat = confusion_matrix(y_test, SVM_preds, normalize='true')\n",
    "\n",
    "SVM_conmat_name = \"svm_confusion_matrix\"\n",
    "SVM_model_name = \"Support Vector Machine\"\n",
    "conmat_to_png(SVM_conmat, class_mapping, Q3_DATA_PATH, SVM_conmat_name, SVM_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409318f8",
   "metadata": {},
   "source": [
    "**Model 3: Decision Tree**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31126be0",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1c3475",
   "metadata": {},
   "outputs": [],
   "source": [
    "DTC = DecisionTreeClassifier(random_state=10, criterion=\"entropy\")\n",
    "DTC.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138f177d",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884ecafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "DTC_preds = DTC.predict(X_test)\n",
    "DTC_summary = classification_report(y_true=y_test, y_pred=DTC_preds, labels=list(class_mapping.keys()), target_names=list(class_mapping.values()), output_dict=True)\n",
    "print(f\"Decision Tree Accuracy: {DTC_summary[\"accuracy\"]}\")\n",
    "\n",
    "DTC_file_name = \"dtc_performance\"\n",
    "dict_to_json(DTC_summary, Q3_DATA_PATH, DTC_file_name)\n",
    "\n",
    "DTC_conmat = confusion_matrix(y_test, DTC_preds, normalize='true')\n",
    "\n",
    "DTC_conmat_name = \"dtc_confusion_matrix\"\n",
    "DTC_model_name = \"Decision Tree\"\n",
    "conmat_to_png(DTC_conmat, class_mapping, Q3_DATA_PATH, DTC_conmat_name, DTC_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7118cd94",
   "metadata": {},
   "source": [
    "Plot and Save Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3ac3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(30,12))\n",
    "plot_tree(decision_tree=DTC, max_depth=3, fontsize=10, feature_names=X_train.columns)\n",
    "\n",
    "DTC_tree_name = \"dtc_tree.png\"\n",
    "DTC_tree_path = os.path.join(Q3_DATA_PATH, DTC_tree_name)\n",
    "os.makedirs(Q3_DATA_PATH, exist_ok=True)\n",
    "\n",
    "fig.savefig(DTC_tree_path) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fce82e3",
   "metadata": {},
   "source": [
    "**Model 4: K-Nearest Neighbours**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf7343b",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6c5073",
   "metadata": {},
   "outputs": [],
   "source": [
    "K_vals = [1, 5, 10, 15, 20]\n",
    "best_accuracy = 0\n",
    "best_KNN = KNeighborsClassifier(n_neighbors=1)\n",
    "best_K = 0\n",
    "KNN_accuracies = []\n",
    "\n",
    "for i in range(len(K_vals)):\n",
    "    KNN_candidate = KNeighborsClassifier(n_neighbors=K_vals[i])\n",
    "\n",
    "    KNN_candidate.fit(X_train, y_train)\n",
    "    KNN_candidate_preds = KNN_candidate.predict(X_test)\n",
    "\n",
    "    KNN_candidate_acc = round(accuracy_score(y_test, KNN_candidate_preds), 2)\n",
    "    KNN_accuracies.append(KNN_candidate_acc)\n",
    "\n",
    "    if KNN_candidate_acc > best_accuracy:\n",
    "        best_KNN = KNN_candidate\n",
    "        best_K = K_vals[i]\n",
    "        best_accuracy = KNN_candidate_acc\n",
    "\n",
    "KNN = best_KNN\n",
    "\n",
    "print(f\"Best K Value: {best_K}\")\n",
    "print(f\"Accuracy: {best_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71c6fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_explore_dict = {\n",
    "    'K': K_vals,\n",
    "    'accuracies': KNN_accuracies\n",
    "}\n",
    "\n",
    "KNN_exp_file_name = \"knn_exploration\"\n",
    "dict_to_json(SVM_explore_dict, Q3_DATA_PATH, KNN_exp_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241cee76",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334b2575",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_preds = KNN.predict(X_test)\n",
    "KNN_summary = classification_report(y_true=y_test, y_pred=KNN_preds, labels=list(class_mapping.keys()), target_names=list(class_mapping.values()), output_dict=True)\n",
    "print(f\"K-Nearest Neighbours Accuracy: {KNN_summary[\"accuracy\"]}\")\n",
    "\n",
    "KNN_file_name = \"knn_performance\"\n",
    "dict_to_json(KNN_summary, Q3_DATA_PATH, KNN_file_name)\n",
    "\n",
    "KNN_conmat = confusion_matrix(y_test, KNN_preds, normalize='true')\n",
    "\n",
    "KNN_conmat_name = \"knn_confusion_matrix\"\n",
    "KNN_model_name = \"K Nearest Neighbours\"\n",
    "conmat_to_png(KNN_conmat, class_mapping, Q3_DATA_PATH, KNN_conmat_name, KNN_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cc06e6",
   "metadata": {},
   "source": [
    "**Model 5: Neural Net**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a245d2d0",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55ab9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = X_train.shape[1]\n",
    "NN = BinaryClassifier(input_size)\n",
    "NN.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093be821",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b17ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_preds = NN.predict(X_test)\n",
    "NN_summary = classification_report(y_true=y_test, y_pred=NN_preds, labels=list(class_mapping.keys()), target_names=list(class_mapping.values()), output_dict=True)\n",
    "\n",
    "print(f\"Neural Network Accuracy: {NN_summary[\"accuracy\"]}\")\n",
    "\n",
    "NN_file_name = \"nn_performance\"\n",
    "dict_to_json(NN_summary, Q3_DATA_PATH, NN_file_name)\n",
    "\n",
    "NN_conmat = confusion_matrix(y_test, NN_preds, normalize='true')\n",
    "\n",
    "NN_conmat_name = \"nn_confusion_matrix\"\n",
    "NN_model_name = \"Neural Network\"\n",
    "conmat_to_png(NN_conmat, class_mapping, Q3_DATA_PATH, NN_conmat_name, NN_model_name)\n",
    "\n",
    "NN_details_file_name = \"nn_details\"\n",
    "NN.print_model_summary(Q3_DATA_PATH, NN_details_file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
