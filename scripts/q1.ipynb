{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68d826d6",
   "metadata": {},
   "source": [
    "# Q1 Ablation Study\n",
    "\n",
    "This notebook orchestrates the feature-engineering ablation for the stock price movement research question using the shared configuration in `assets/config.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2318326",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os, sys\n",
    "MAIN_PATH = Path(os.getcwd()).parent\n",
    "sys.path.append(str(MAIN_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f24df8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Mapping, Sequence\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "from data_processings.datasets import StockMarketDataset\n",
    "from data_processings.pipeline_builder import build_pipeline_from_config, load_pipeline_config\n",
    "from data_processings.transforms import DFXPipeline\n",
    "from models import build_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc24007b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_DIR = Path(MAIN_PATH, \"assets/configs/q1\")\n",
    "PROFILE_CONFIGS = {path.stem: path for path in sorted(CONFIG_DIR.glob(\"*.json\"))}\n",
    "if not PROFILE_CONFIGS:\n",
    "    raise RuntimeError(\"No preprocessing configs found under assets/configs/q1\")\n",
    "\n",
    "dataset_loader = StockMarketDataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de2fc2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_time_series_frame(df: pd.DataFrame, split_cfg: Mapping[str, object]) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    method = split_cfg.get(\"method\", \"time\")\n",
    "    if method != \"time\":\n",
    "        raise ValueError(\"Only time-based splits are supported in this notebook\")\n",
    "    test_size = float(split_cfg.get(\"test_size\", 0.2))\n",
    "    split_idx = int(len(df) * (1 - test_size))\n",
    "    split_idx = max(1, min(split_idx, len(df) - 1))\n",
    "    return df.iloc[:split_idx].copy(), df.iloc[split_idx:].copy()\n",
    "\n",
    "\n",
    "def sanitize_features_target(features: pd.DataFrame, target: pd.Series) -> tuple[pd.DataFrame, pd.Series]:\n",
    "    target_name = target.name or \"target\"\n",
    "    combined = pd.concat([features, target.rename(target_name)], axis=1)\n",
    "    combined = combined.replace([np.inf, -np.inf], np.nan).dropna(axis=0)\n",
    "    cleaned_target = combined[target_name]\n",
    "    cleaned_features = combined.drop(columns=[target_name])\n",
    "    return cleaned_features, cleaned_target\n",
    "\n",
    "\n",
    "def load_dataset_for_config(cfg: Mapping[str, object]) -> pd.DataFrame:\n",
    "    options = cfg.get(\"dataset_options\", {})\n",
    "    if \"tickers\" not in options:\n",
    "        raise ValueError(\"StockMarketDataset requires 'dataset_options.tickers'\")\n",
    "    return dataset_loader.load(options)\n",
    "\n",
    "\n",
    "def prepare_pipeline_frames(raw_df: pd.DataFrame, pipeline: DFXPipeline, split_cfg: Mapping[str, object]) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    processed = pipeline.apply_global(raw_df)\n",
    "    processed = processed.replace([np.inf, -np.inf], np.nan).dropna(axis=0)\n",
    "    train_df, test_df = split_time_series_frame(processed, split_cfg)\n",
    "    train_df = pipeline.fit_transform(train_df)\n",
    "    test_df = pipeline.transform(test_df)\n",
    "    return train_df, test_df\n",
    "\n",
    "\n",
    "def prepare_feature_matrices(\n",
    "    train_df: pd.DataFrame,\n",
    "    test_df: pd.DataFrame,\n",
    "    target_column: str,\n",
    "    drop_columns: Sequence[str]\n",
    ") -> tuple[pd.DataFrame, pd.Series, pd.DataFrame, pd.Series]:\n",
    "    if target_column not in train_df.columns or target_column not in test_df.columns:\n",
    "        raise KeyError(f\"Target column '{target_column}' missing from processed frames.\")\n",
    "    drop_list = list(drop_columns)\n",
    "    y_train = train_df[target_column].copy()\n",
    "    y_test = test_df[target_column].copy()\n",
    "    features_train = train_df.drop(columns=drop_list + [target_column], errors=\"ignore\")\n",
    "    features_test = test_df.drop(columns=drop_list + [target_column], errors=\"ignore\")\n",
    "    features_train = features_train.select_dtypes(include=[np.number])\n",
    "    features_test = features_test.select_dtypes(include=[np.number])\n",
    "    features_train, y_train = sanitize_features_target(features_train, y_train)\n",
    "    features_test, y_test = sanitize_features_target(features_test, y_test)\n",
    "    features_test = features_test.reindex(columns=features_train.columns, fill_value=0.0)\n",
    "    return features_train, y_train, features_test, y_test\n",
    "\n",
    "\n",
    "def evaluate_model(\n",
    "    model_key: str,\n",
    "    X_train: pd.DataFrame,\n",
    "    y_train: pd.Series,\n",
    "    X_test: pd.DataFrame,\n",
    "    y_test: pd.Series,\n",
    "    metrics: Sequence[str],\n",
    ") -> dict[str, float]:\n",
    "    model = build_model(model_key)\n",
    "    model.fit(X_train.to_numpy(dtype=np.float64), y_train.to_numpy())\n",
    "    predictions = model.predict(X_test.to_numpy(dtype=np.float64))\n",
    "\n",
    "    results: dict[str, float] = {}\n",
    "    for metric in metrics:\n",
    "        if metric == \"accuracy\":\n",
    "            results[\"accuracy\"] = accuracy_score(y_test, predictions)\n",
    "        elif metric == \"f1\":\n",
    "            results[\"f1\"] = f1_score(y_test, predictions, zero_division=0)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported metric: {metric}\")\n",
    "    return results\n",
    "\n",
    "\n",
    "def run_profile(profile_name: str, cfg_path: Path) -> list[dict[str, object]]:\n",
    "    cfg = load_pipeline_config(cfg_path)\n",
    "    pipeline, metadata = build_pipeline_from_config(cfg)\n",
    "    raw_df = load_dataset_for_config(cfg)\n",
    "    split_cfg = cfg.get(\"split\", {})\n",
    "    train_df, test_df = prepare_pipeline_frames(raw_df, pipeline, split_cfg)\n",
    "\n",
    "    target_column = str(metadata.get(\"target_column\", cfg.get(\"target_column\", \"target\")))\n",
    "    drop_columns = metadata.get(\"drop_columns\", cfg.get(\"drop_columns\", [])) or []\n",
    "    models = cfg.get(\"models\", [])\n",
    "    metrics = cfg.get(\"metrics\", [\"accuracy\"])\n",
    "\n",
    "    X_train, y_train, X_test, y_test = prepare_feature_matrices(train_df, test_df, target_column, drop_columns)\n",
    "    if len(X_train) < 10 or len(X_test) < 5:\n",
    "        return []\n",
    "\n",
    "    records: list[dict[str, object]] = []\n",
    "    for model_key in models:\n",
    "        metric_values = evaluate_model(model_key, X_train, y_train, X_test, y_test, metrics)\n",
    "        record = {\n",
    "            \"config\": profile_name,\n",
    "            \"model\": model_key,\n",
    "            \"train_samples\": len(X_train),\n",
    "            \"test_samples\": len(X_test),\n",
    "            \"num_features\": X_train.shape[1],\n",
    "        }\n",
    "        record.update(metric_values)\n",
    "        records.append(record)\n",
    "\n",
    "    return records\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf1ee575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>config</th>\n",
       "      <th>model</th>\n",
       "      <th>train_samples</th>\n",
       "      <th>test_samples</th>\n",
       "      <th>num_features</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P0_baseline</td>\n",
       "      <td>decision_tree</td>\n",
       "      <td>2572</td>\n",
       "      <td>644</td>\n",
       "      <td>36</td>\n",
       "      <td>0.532609</td>\n",
       "      <td>0.426667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P0_baseline</td>\n",
       "      <td>gradient_boosting</td>\n",
       "      <td>2572</td>\n",
       "      <td>644</td>\n",
       "      <td>36</td>\n",
       "      <td>0.506211</td>\n",
       "      <td>0.487097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P0_baseline</td>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>2572</td>\n",
       "      <td>644</td>\n",
       "      <td>36</td>\n",
       "      <td>0.559006</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P0_baseline</td>\n",
       "      <td>naive_bayes</td>\n",
       "      <td>2572</td>\n",
       "      <td>644</td>\n",
       "      <td>36</td>\n",
       "      <td>0.526398</td>\n",
       "      <td>0.442413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P0_baseline</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>2572</td>\n",
       "      <td>644</td>\n",
       "      <td>36</td>\n",
       "      <td>0.531056</td>\n",
       "      <td>0.044304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>P0_baseline</td>\n",
       "      <td>svm</td>\n",
       "      <td>2572</td>\n",
       "      <td>644</td>\n",
       "      <td>36</td>\n",
       "      <td>0.559006</td>\n",
       "      <td>0.006993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>P1_median_mode_no_indicator</td>\n",
       "      <td>decision_tree</td>\n",
       "      <td>2572</td>\n",
       "      <td>644</td>\n",
       "      <td>36</td>\n",
       "      <td>0.532609</td>\n",
       "      <td>0.426667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>P1_median_mode_no_indicator</td>\n",
       "      <td>gradient_boosting</td>\n",
       "      <td>2572</td>\n",
       "      <td>644</td>\n",
       "      <td>36</td>\n",
       "      <td>0.506211</td>\n",
       "      <td>0.487097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>P1_median_mode_no_indicator</td>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>2572</td>\n",
       "      <td>644</td>\n",
       "      <td>36</td>\n",
       "      <td>0.559006</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>P1_median_mode_no_indicator</td>\n",
       "      <td>naive_bayes</td>\n",
       "      <td>2572</td>\n",
       "      <td>644</td>\n",
       "      <td>36</td>\n",
       "      <td>0.526398</td>\n",
       "      <td>0.442413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>P1_median_mode_no_indicator</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>2572</td>\n",
       "      <td>644</td>\n",
       "      <td>36</td>\n",
       "      <td>0.531056</td>\n",
       "      <td>0.044304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>P1_median_mode_no_indicator</td>\n",
       "      <td>svm</td>\n",
       "      <td>2572</td>\n",
       "      <td>644</td>\n",
       "      <td>36</td>\n",
       "      <td>0.559006</td>\n",
       "      <td>0.006993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>P2_robust_scaler_winsorize</td>\n",
       "      <td>decision_tree</td>\n",
       "      <td>2572</td>\n",
       "      <td>644</td>\n",
       "      <td>36</td>\n",
       "      <td>0.541925</td>\n",
       "      <td>0.411178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>P2_robust_scaler_winsorize</td>\n",
       "      <td>gradient_boosting</td>\n",
       "      <td>2572</td>\n",
       "      <td>644</td>\n",
       "      <td>36</td>\n",
       "      <td>0.552795</td>\n",
       "      <td>0.186441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>P2_robust_scaler_winsorize</td>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>2572</td>\n",
       "      <td>644</td>\n",
       "      <td>36</td>\n",
       "      <td>0.559006</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>P2_robust_scaler_winsorize</td>\n",
       "      <td>naive_bayes</td>\n",
       "      <td>2572</td>\n",
       "      <td>644</td>\n",
       "      <td>36</td>\n",
       "      <td>0.526398</td>\n",
       "      <td>0.442413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>P2_robust_scaler_winsorize</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>2572</td>\n",
       "      <td>644</td>\n",
       "      <td>36</td>\n",
       "      <td>0.548137</td>\n",
       "      <td>0.064309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>P2_robust_scaler_winsorize</td>\n",
       "      <td>svm</td>\n",
       "      <td>2572</td>\n",
       "      <td>644</td>\n",
       "      <td>36</td>\n",
       "      <td>0.559006</td>\n",
       "      <td>0.006993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>P3_minmax_global</td>\n",
       "      <td>decision_tree</td>\n",
       "      <td>2572</td>\n",
       "      <td>644</td>\n",
       "      <td>36</td>\n",
       "      <td>0.529503</td>\n",
       "      <td>0.452080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>P3_minmax_global</td>\n",
       "      <td>gradient_boosting</td>\n",
       "      <td>2572</td>\n",
       "      <td>644</td>\n",
       "      <td>36</td>\n",
       "      <td>0.527950</td>\n",
       "      <td>0.361345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>P3_minmax_global</td>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>2572</td>\n",
       "      <td>644</td>\n",
       "      <td>36</td>\n",
       "      <td>0.559006</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>P3_minmax_global</td>\n",
       "      <td>naive_bayes</td>\n",
       "      <td>2572</td>\n",
       "      <td>644</td>\n",
       "      <td>36</td>\n",
       "      <td>0.526398</td>\n",
       "      <td>0.442413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>P3_minmax_global</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>2572</td>\n",
       "      <td>644</td>\n",
       "      <td>36</td>\n",
       "      <td>0.513975</td>\n",
       "      <td>0.410546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>P3_minmax_global</td>\n",
       "      <td>svm</td>\n",
       "      <td>2572</td>\n",
       "      <td>644</td>\n",
       "      <td>36</td>\n",
       "      <td>0.559006</td>\n",
       "      <td>0.006993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>P4_no_scaling</td>\n",
       "      <td>decision_tree</td>\n",
       "      <td>2572</td>\n",
       "      <td>644</td>\n",
       "      <td>36</td>\n",
       "      <td>0.489130</td>\n",
       "      <td>0.396330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>P4_no_scaling</td>\n",
       "      <td>gradient_boosting</td>\n",
       "      <td>2572</td>\n",
       "      <td>644</td>\n",
       "      <td>36</td>\n",
       "      <td>0.540373</td>\n",
       "      <td>0.415020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>P4_no_scaling</td>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>2572</td>\n",
       "      <td>644</td>\n",
       "      <td>36</td>\n",
       "      <td>0.554348</td>\n",
       "      <td>0.213699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>P4_no_scaling</td>\n",
       "      <td>naive_bayes</td>\n",
       "      <td>2572</td>\n",
       "      <td>644</td>\n",
       "      <td>36</td>\n",
       "      <td>0.498447</td>\n",
       "      <td>0.524300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>P4_no_scaling</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>2572</td>\n",
       "      <td>644</td>\n",
       "      <td>36</td>\n",
       "      <td>0.523292</td>\n",
       "      <td>0.389662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>P4_no_scaling</td>\n",
       "      <td>svm</td>\n",
       "      <td>2572</td>\n",
       "      <td>644</td>\n",
       "      <td>36</td>\n",
       "      <td>0.559006</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>P5_short_windows_returns</td>\n",
       "      <td>decision_tree</td>\n",
       "      <td>2572</td>\n",
       "      <td>644</td>\n",
       "      <td>39</td>\n",
       "      <td>0.517081</td>\n",
       "      <td>0.457243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>P5_short_windows_returns</td>\n",
       "      <td>gradient_boosting</td>\n",
       "      <td>2572</td>\n",
       "      <td>644</td>\n",
       "      <td>39</td>\n",
       "      <td>0.541925</td>\n",
       "      <td>0.466546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>P5_short_windows_returns</td>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>2572</td>\n",
       "      <td>644</td>\n",
       "      <td>39</td>\n",
       "      <td>0.559006</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>P5_short_windows_returns</td>\n",
       "      <td>naive_bayes</td>\n",
       "      <td>2572</td>\n",
       "      <td>644</td>\n",
       "      <td>39</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.435897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>P5_short_windows_returns</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>2572</td>\n",
       "      <td>644</td>\n",
       "      <td>39</td>\n",
       "      <td>0.554348</td>\n",
       "      <td>0.158358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>P5_short_windows_returns</td>\n",
       "      <td>svm</td>\n",
       "      <td>2572</td>\n",
       "      <td>644</td>\n",
       "      <td>39</td>\n",
       "      <td>0.559006</td>\n",
       "      <td>0.006993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         config                model  train_samples  \\\n",
       "0                   P0_baseline        decision_tree           2572   \n",
       "1                   P0_baseline    gradient_boosting           2572   \n",
       "2                   P0_baseline  logistic_regression           2572   \n",
       "3                   P0_baseline          naive_bayes           2572   \n",
       "4                   P0_baseline        random_forest           2572   \n",
       "5                   P0_baseline                  svm           2572   \n",
       "6   P1_median_mode_no_indicator        decision_tree           2572   \n",
       "7   P1_median_mode_no_indicator    gradient_boosting           2572   \n",
       "8   P1_median_mode_no_indicator  logistic_regression           2572   \n",
       "9   P1_median_mode_no_indicator          naive_bayes           2572   \n",
       "10  P1_median_mode_no_indicator        random_forest           2572   \n",
       "11  P1_median_mode_no_indicator                  svm           2572   \n",
       "12   P2_robust_scaler_winsorize        decision_tree           2572   \n",
       "13   P2_robust_scaler_winsorize    gradient_boosting           2572   \n",
       "14   P2_robust_scaler_winsorize  logistic_regression           2572   \n",
       "15   P2_robust_scaler_winsorize          naive_bayes           2572   \n",
       "16   P2_robust_scaler_winsorize        random_forest           2572   \n",
       "17   P2_robust_scaler_winsorize                  svm           2572   \n",
       "18             P3_minmax_global        decision_tree           2572   \n",
       "19             P3_minmax_global    gradient_boosting           2572   \n",
       "20             P3_minmax_global  logistic_regression           2572   \n",
       "21             P3_minmax_global          naive_bayes           2572   \n",
       "22             P3_minmax_global        random_forest           2572   \n",
       "23             P3_minmax_global                  svm           2572   \n",
       "24                P4_no_scaling        decision_tree           2572   \n",
       "25                P4_no_scaling    gradient_boosting           2572   \n",
       "26                P4_no_scaling  logistic_regression           2572   \n",
       "27                P4_no_scaling          naive_bayes           2572   \n",
       "28                P4_no_scaling        random_forest           2572   \n",
       "29                P4_no_scaling                  svm           2572   \n",
       "30     P5_short_windows_returns        decision_tree           2572   \n",
       "31     P5_short_windows_returns    gradient_boosting           2572   \n",
       "32     P5_short_windows_returns  logistic_regression           2572   \n",
       "33     P5_short_windows_returns          naive_bayes           2572   \n",
       "34     P5_short_windows_returns        random_forest           2572   \n",
       "35     P5_short_windows_returns                  svm           2572   \n",
       "\n",
       "    test_samples  num_features  accuracy        f1  \n",
       "0            644            36  0.532609  0.426667  \n",
       "1            644            36  0.506211  0.487097  \n",
       "2            644            36  0.559006  0.000000  \n",
       "3            644            36  0.526398  0.442413  \n",
       "4            644            36  0.531056  0.044304  \n",
       "5            644            36  0.559006  0.006993  \n",
       "6            644            36  0.532609  0.426667  \n",
       "7            644            36  0.506211  0.487097  \n",
       "8            644            36  0.559006  0.000000  \n",
       "9            644            36  0.526398  0.442413  \n",
       "10           644            36  0.531056  0.044304  \n",
       "11           644            36  0.559006  0.006993  \n",
       "12           644            36  0.541925  0.411178  \n",
       "13           644            36  0.552795  0.186441  \n",
       "14           644            36  0.559006  0.000000  \n",
       "15           644            36  0.526398  0.442413  \n",
       "16           644            36  0.548137  0.064309  \n",
       "17           644            36  0.559006  0.006993  \n",
       "18           644            36  0.529503  0.452080  \n",
       "19           644            36  0.527950  0.361345  \n",
       "20           644            36  0.559006  0.000000  \n",
       "21           644            36  0.526398  0.442413  \n",
       "22           644            36  0.513975  0.410546  \n",
       "23           644            36  0.559006  0.006993  \n",
       "24           644            36  0.489130  0.396330  \n",
       "25           644            36  0.540373  0.415020  \n",
       "26           644            36  0.554348  0.213699  \n",
       "27           644            36  0.498447  0.524300  \n",
       "28           644            36  0.523292  0.389662  \n",
       "29           644            36  0.559006  0.000000  \n",
       "30           644            39  0.517081  0.457243  \n",
       "31           644            39  0.541925  0.466546  \n",
       "32           644            39  0.559006  0.000000  \n",
       "33           644            39  0.521739  0.435897  \n",
       "34           644            39  0.554348  0.158358  \n",
       "35           644            39  0.559006  0.006993  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_records: list[dict[str, object]] = []\n",
    "for profile_name, cfg_path in PROFILE_CONFIGS.items():\n",
    "    profile_records = run_profile(profile_name, cfg_path)\n",
    "    all_records.extend(profile_records)\n",
    "\n",
    "results_df = pd.DataFrame(all_records)\n",
    "if not results_df.empty:\n",
    "    sort_columns = [column for column in [\"config\", \"model\"] if column in results_df.columns]\n",
    "    if sort_columns:\n",
    "        results_df = results_df.sort_values(sort_columns).reset_index(drop=True)\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e175b92",
   "metadata": {},
   "source": [
    "## Notes\n",
    "- All preprocessing and model definitions are sourced from `assets/config.json`.\n",
    "- Extend the experiment by editing the configuration (e.g., add feature sets or models) and re-running the notebook.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
