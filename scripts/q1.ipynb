{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68d826d6",
   "metadata": {},
   "source": [
    "# Q1 Ablation Study\n",
    "\n",
    "This notebook orchestrates the feature-engineering ablation for the stock price movement research question using the shared configuration in `assets/config.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f24df8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os, sys\n",
    "sys.path.append(str(Path(os.getcwd()).parent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc24007b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from typing import Mapping, Sequence\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "from data_processings import (\n",
    "    append_target,\n",
    "    apply_base_preprocessing,\n",
    "    apply_feature_sets,\n",
    "    apply_post_split_transforms,\n",
    "    balance_training_dataframe,\n",
    "    get_experiment_config,\n",
    "    get_preprocessing_config,\n",
    "    load_config,\n",
    "    load_stock_market_data,\n",
    "    select_feature_columns,\n",
    ")\n",
    "from models import build_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de2fc2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = load_config()\n",
    "EXPERIMENT_KEY = \"q1_stock_movement\"\n",
    "EXPERIMENT_CFG = get_experiment_config(EXPERIMENT_KEY)\n",
    "DATASET_KEY = EXPERIMENT_CFG[\"dataset\"]\n",
    "PREPROCESSING_CFG = get_preprocessing_config(DATASET_KEY)\n",
    "\n",
    "\n",
    "def load_dataset() -> pd.DataFrame:\n",
    "    options = EXPERIMENT_CFG.get(\"dataset_options\", {})\n",
    "    tickers = options.get(\"tickers\")\n",
    "    if not tickers:\n",
    "        raise ValueError(\"Experiment dataset options must define 'tickers'\")\n",
    "    dataset_kwargs = {key: value for key, value in options.items() if key != \"tickers\"}\n",
    "    return load_stock_market_data(tickers, **dataset_kwargs)\n",
    "\n",
    "\n",
    "def sanitize_features_target(\n",
    "    features: pd.DataFrame,\n",
    "    target: pd.Series,\n",
    ") -> tuple[pd.DataFrame, pd.Series]:\n",
    "    target_name = target.name or \"target\"\n",
    "    combined = pd.concat([features, target.rename(target_name)], axis=1)\n",
    "    combined = combined.replace([np.inf, -np.inf], np.nan).dropna(axis=0)\n",
    "    cleaned_target = combined[target_name]\n",
    "    cleaned_features = combined.drop(columns=[target_name])\n",
    "    return cleaned_features, cleaned_target\n",
    "\n",
    "\n",
    "def split_time_series_frame(\n",
    "    df: pd.DataFrame,\n",
    "    split_cfg: Mapping[str, object],\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    if split_cfg.get(\"method\", \"time\") != \"time\":\n",
    "        raise ValueError(\"Only time-based splits are supported in this notebook\")\n",
    "\n",
    "    test_size = float(split_cfg.get(\"test_size\", 0.2))\n",
    "    split_idx = int(len(df) * (1 - test_size))\n",
    "    split_idx = max(1, min(split_idx, len(df) - 1))\n",
    "    return df.iloc[:split_idx].copy(), df.iloc[split_idx:].copy()\n",
    "\n",
    "\n",
    "def prepare_labelled_frame(\n",
    "    base_df: pd.DataFrame,\n",
    "    feature_sets: Sequence[str],\n",
    "    profile_config: Mapping[str, object],\n",
    ") -> pd.DataFrame:\n",
    "    enriched = apply_feature_sets(\n",
    "        base_df,\n",
    "        DATASET_KEY,\n",
    "        feature_sets,\n",
    "        config_override=profile_config,\n",
    "    )\n",
    "    labelled = append_target(\n",
    "        enriched,\n",
    "        DATASET_KEY,\n",
    "        config_override=profile_config,\n",
    "    )\n",
    "    return labelled.replace([np.inf, -np.inf], np.nan).dropna(axis=0)\n",
    "\n",
    "\n",
    "def evaluate_model(\n",
    "    model_key: str,\n",
    "    X_train: pd.DataFrame,\n",
    "    y_train: pd.Series,\n",
    "    X_test: pd.DataFrame,\n",
    "    y_test: pd.Series,\n",
    "    metrics: Sequence[str],\n",
    ") -> dict:\n",
    "    model = build_model(model_key)\n",
    "    model.fit(X_train.values, y_train.values)\n",
    "    predictions = model.predict(X_test.values)\n",
    "\n",
    "    results: dict[str, float] = {}\n",
    "    for metric in metrics:\n",
    "        if metric == \"accuracy\":\n",
    "            results[\"accuracy\"] = accuracy_score(y_test, predictions)\n",
    "        elif metric == \"f1\":\n",
    "            results[\"f1\"] = f1_score(y_test, predictions, zero_division=0)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported metric: {metric}\")\n",
    "    return results\n",
    "\n",
    "\n",
    "def run_ablation(raw_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    ablation_axis = EXPERIMENT_CFG.get(\"ablation_axis\", \"features\")\n",
    "    ablation_sets_key = EXPERIMENT_CFG.get(\"ablation_sets_key\")\n",
    "    if not ablation_sets_key:\n",
    "        raise KeyError(\"Experiment configuration missing 'ablation_sets_key'\")\n",
    "\n",
    "    split_cfg = EXPERIMENT_CFG.get(\"split\", {})\n",
    "    metrics = EXPERIMENT_CFG.get(\"metrics\", [\"accuracy\"])\n",
    "    models = EXPERIMENT_CFG.get(\"models\", [])\n",
    "\n",
    "    records: list[dict[str, object]] = []\n",
    "\n",
    "    if ablation_axis == \"preprocessing\":\n",
    "        profile_names = PREPROCESSING_CFG.get(ablation_sets_key)\n",
    "        if not profile_names:\n",
    "            raise KeyError(f\"No preprocessing profiles defined under key '{ablation_sets_key}'\")\n",
    "\n",
    "        feature_sets_fixed = EXPERIMENT_CFG.get(\"feature_sets_fixed\") or [\"technical\"]\n",
    "\n",
    "        for profile_name in profile_names:\n",
    "            base_df, profile_config = apply_base_preprocessing(\n",
    "                raw_df,\n",
    "                DATASET_KEY,\n",
    "                profile_name=profile_name,\n",
    "            )\n",
    "            labelled = prepare_labelled_frame(base_df, feature_sets_fixed, profile_config)\n",
    "            if len(labelled) < 10:\n",
    "                continue\n",
    "\n",
    "            train_df, test_df = split_time_series_frame(labelled, split_cfg)\n",
    "            train_df = balance_training_dataframe(train_df, DATASET_KEY, config_override=profile_config)\n",
    "            train_df, test_df = apply_post_split_transforms(train_df, test_df, profile_config)\n",
    "\n",
    "            train_features, y_train = select_feature_columns(\n",
    "                train_df,\n",
    "                DATASET_KEY,\n",
    "                config_override=profile_config,\n",
    "            )\n",
    "            test_features, y_test = select_feature_columns(\n",
    "                test_df,\n",
    "                DATASET_KEY,\n",
    "                config_override=profile_config,\n",
    "            )\n",
    "\n",
    "            train_features, y_train = sanitize_features_target(train_features, y_train)\n",
    "            test_features, y_test = sanitize_features_target(test_features, y_test)\n",
    "            if len(train_features) < 10 or len(test_features) < 5:\n",
    "                continue\n",
    "\n",
    "            test_features = test_features.reindex(columns=train_features.columns, fill_value=0.0)\n",
    "\n",
    "            for model_key in models:\n",
    "                metric_values = evaluate_model(model_key, train_features, y_train, test_features, y_test, metrics)\n",
    "                record = {\n",
    "                    \"preproc_profile\": profile_name,\n",
    "                    \"feature_sets\": \", \".join(feature_sets_fixed),\n",
    "                    \"model\": model_key,\n",
    "                    \"train_samples\": len(train_features),\n",
    "                    \"test_samples\": len(test_features),\n",
    "                    \"num_features\": train_features.shape[1],\n",
    "                }\n",
    "                record.update(metric_values)\n",
    "                records.append(record)\n",
    "    else:\n",
    "        feature_combinations = PREPROCESSING_CFG.get(ablation_sets_key)\n",
    "        if not feature_combinations:\n",
    "            raise KeyError(f\"No feature sets defined under key '{ablation_sets_key}'\")\n",
    "\n",
    "        base_df, base_config = apply_base_preprocessing(raw_df, DATASET_KEY)\n",
    "\n",
    "        for feature_sets in feature_combinations:\n",
    "            labelled = prepare_labelled_frame(base_df, feature_sets, base_config)\n",
    "            if len(labelled) < 10:\n",
    "                continue\n",
    "\n",
    "            train_df, test_df = split_time_series_frame(labelled, split_cfg)\n",
    "            train_df = balance_training_dataframe(train_df, DATASET_KEY, config_override=base_config)\n",
    "            train_df, test_df = apply_post_split_transforms(train_df, test_df, base_config)\n",
    "\n",
    "            train_features, y_train = select_feature_columns(\n",
    "                train_df,\n",
    "                DATASET_KEY,\n",
    "                config_override=base_config,\n",
    "            )\n",
    "            test_features, y_test = select_feature_columns(\n",
    "                test_df,\n",
    "                DATASET_KEY,\n",
    "                config_override=base_config,\n",
    "            )\n",
    "\n",
    "            train_features, y_train = sanitize_features_target(train_features, y_train)\n",
    "            test_features, y_test = sanitize_features_target(test_features, y_test)\n",
    "            if len(train_features) < 10 or len(test_features) < 5:\n",
    "                continue\n",
    "\n",
    "            test_features = test_features.reindex(columns=train_features.columns, fill_value=0.0)\n",
    "\n",
    "            for model_key in models:\n",
    "                metric_values = evaluate_model(model_key, train_features, y_train, test_features, y_test, metrics)\n",
    "                record = {\n",
    "                    \"preproc_profile\": \"default\",\n",
    "                    \"feature_sets\": \", \".join(feature_sets),\n",
    "                    \"model\": model_key,\n",
    "                    \"train_samples\": len(train_features),\n",
    "                    \"test_samples\": len(test_features),\n",
    "                    \"num_features\": train_features.shape[1],\n",
    "                }\n",
    "                record.update(metric_values)\n",
    "                records.append(record)\n",
    "\n",
    "    return pd.DataFrame(records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf1ee575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preproc_profile</th>\n",
       "      <th>feature_sets</th>\n",
       "      <th>model</th>\n",
       "      <th>train_samples</th>\n",
       "      <th>test_samples</th>\n",
       "      <th>num_features</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P0_baseline</td>\n",
       "      <td>technical, sentiment, macro</td>\n",
       "      <td>decision_tree</td>\n",
       "      <td>2572</td>\n",
       "      <td>644</td>\n",
       "      <td>44</td>\n",
       "      <td>0.557453</td>\n",
       "      <td>0.435644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P0_baseline</td>\n",
       "      <td>technical, sentiment, macro</td>\n",
       "      <td>gradient_boosting</td>\n",
       "      <td>2572</td>\n",
       "      <td>644</td>\n",
       "      <td>44</td>\n",
       "      <td>0.531056</td>\n",
       "      <td>0.452899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P0_baseline</td>\n",
       "      <td>technical, sentiment, macro</td>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>2572</td>\n",
       "      <td>644</td>\n",
       "      <td>44</td>\n",
       "      <td>0.559006</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P0_baseline</td>\n",
       "      <td>technical, sentiment, macro</td>\n",
       "      <td>naive_bayes</td>\n",
       "      <td>2572</td>\n",
       "      <td>644</td>\n",
       "      <td>44</td>\n",
       "      <td>0.526398</td>\n",
       "      <td>0.442413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P0_baseline</td>\n",
       "      <td>technical, sentiment, macro</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>2572</td>\n",
       "      <td>644</td>\n",
       "      <td>44</td>\n",
       "      <td>0.555901</td>\n",
       "      <td>0.052980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>P0_baseline</td>\n",
       "      <td>technical, sentiment, macro</td>\n",
       "      <td>svm</td>\n",
       "      <td>2572</td>\n",
       "      <td>644</td>\n",
       "      <td>44</td>\n",
       "      <td>0.559006</td>\n",
       "      <td>0.006993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>P1_median_mode_no_indicator</td>\n",
       "      <td>technical, sentiment, macro</td>\n",
       "      <td>decision_tree</td>\n",
       "      <td>2572</td>\n",
       "      <td>644</td>\n",
       "      <td>36</td>\n",
       "      <td>0.543478</td>\n",
       "      <td>0.423529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>P1_median_mode_no_indicator</td>\n",
       "      <td>technical, sentiment, macro</td>\n",
       "      <td>gradient_boosting</td>\n",
       "      <td>2572</td>\n",
       "      <td>644</td>\n",
       "      <td>36</td>\n",
       "      <td>0.501553</td>\n",
       "      <td>0.499220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>P1_median_mode_no_indicator</td>\n",
       "      <td>technical, sentiment, macro</td>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>2572</td>\n",
       "      <td>644</td>\n",
       "      <td>36</td>\n",
       "      <td>0.559006</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>P1_median_mode_no_indicator</td>\n",
       "      <td>technical, sentiment, macro</td>\n",
       "      <td>naive_bayes</td>\n",
       "      <td>2572</td>\n",
       "      <td>644</td>\n",
       "      <td>36</td>\n",
       "      <td>0.526398</td>\n",
       "      <td>0.442413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>P1_median_mode_no_indicator</td>\n",
       "      <td>technical, sentiment, macro</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>2572</td>\n",
       "      <td>644</td>\n",
       "      <td>36</td>\n",
       "      <td>0.568323</td>\n",
       "      <td>0.125786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>P1_median_mode_no_indicator</td>\n",
       "      <td>technical, sentiment, macro</td>\n",
       "      <td>svm</td>\n",
       "      <td>2572</td>\n",
       "      <td>644</td>\n",
       "      <td>36</td>\n",
       "      <td>0.559006</td>\n",
       "      <td>0.006993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>P2_robust_scaler_winsorize</td>\n",
       "      <td>technical, sentiment, macro</td>\n",
       "      <td>decision_tree</td>\n",
       "      <td>2572</td>\n",
       "      <td>644</td>\n",
       "      <td>44</td>\n",
       "      <td>0.543478</td>\n",
       "      <td>0.425781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>P2_robust_scaler_winsorize</td>\n",
       "      <td>technical, sentiment, macro</td>\n",
       "      <td>gradient_boosting</td>\n",
       "      <td>2572</td>\n",
       "      <td>644</td>\n",
       "      <td>44</td>\n",
       "      <td>0.552795</td>\n",
       "      <td>0.186441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>P2_robust_scaler_winsorize</td>\n",
       "      <td>technical, sentiment, macro</td>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>2572</td>\n",
       "      <td>644</td>\n",
       "      <td>44</td>\n",
       "      <td>0.559006</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>P2_robust_scaler_winsorize</td>\n",
       "      <td>technical, sentiment, macro</td>\n",
       "      <td>naive_bayes</td>\n",
       "      <td>2572</td>\n",
       "      <td>644</td>\n",
       "      <td>44</td>\n",
       "      <td>0.526398</td>\n",
       "      <td>0.442413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>P2_robust_scaler_winsorize</td>\n",
       "      <td>technical, sentiment, macro</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>2572</td>\n",
       "      <td>644</td>\n",
       "      <td>44</td>\n",
       "      <td>0.548137</td>\n",
       "      <td>0.120846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>P2_robust_scaler_winsorize</td>\n",
       "      <td>technical, sentiment, macro</td>\n",
       "      <td>svm</td>\n",
       "      <td>2572</td>\n",
       "      <td>644</td>\n",
       "      <td>44</td>\n",
       "      <td>0.559006</td>\n",
       "      <td>0.006993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>P3_minmax_global</td>\n",
       "      <td>technical, sentiment, macro</td>\n",
       "      <td>decision_tree</td>\n",
       "      <td>2572</td>\n",
       "      <td>644</td>\n",
       "      <td>44</td>\n",
       "      <td>0.515528</td>\n",
       "      <td>0.417910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>P3_minmax_global</td>\n",
       "      <td>technical, sentiment, macro</td>\n",
       "      <td>gradient_boosting</td>\n",
       "      <td>2572</td>\n",
       "      <td>644</td>\n",
       "      <td>44</td>\n",
       "      <td>0.531056</td>\n",
       "      <td>0.365546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>P3_minmax_global</td>\n",
       "      <td>technical, sentiment, macro</td>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>2572</td>\n",
       "      <td>644</td>\n",
       "      <td>44</td>\n",
       "      <td>0.559006</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>P3_minmax_global</td>\n",
       "      <td>technical, sentiment, macro</td>\n",
       "      <td>naive_bayes</td>\n",
       "      <td>2572</td>\n",
       "      <td>644</td>\n",
       "      <td>44</td>\n",
       "      <td>0.526398</td>\n",
       "      <td>0.442413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>P3_minmax_global</td>\n",
       "      <td>technical, sentiment, macro</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>2572</td>\n",
       "      <td>644</td>\n",
       "      <td>44</td>\n",
       "      <td>0.515528</td>\n",
       "      <td>0.395349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>P3_minmax_global</td>\n",
       "      <td>technical, sentiment, macro</td>\n",
       "      <td>svm</td>\n",
       "      <td>2572</td>\n",
       "      <td>644</td>\n",
       "      <td>44</td>\n",
       "      <td>0.559006</td>\n",
       "      <td>0.006993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>P4_no_scaling</td>\n",
       "      <td>technical, sentiment, macro</td>\n",
       "      <td>decision_tree</td>\n",
       "      <td>2572</td>\n",
       "      <td>644</td>\n",
       "      <td>44</td>\n",
       "      <td>0.503106</td>\n",
       "      <td>0.416058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>P4_no_scaling</td>\n",
       "      <td>technical, sentiment, macro</td>\n",
       "      <td>gradient_boosting</td>\n",
       "      <td>2572</td>\n",
       "      <td>644</td>\n",
       "      <td>44</td>\n",
       "      <td>0.531056</td>\n",
       "      <td>0.398406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>P4_no_scaling</td>\n",
       "      <td>technical, sentiment, macro</td>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>2572</td>\n",
       "      <td>644</td>\n",
       "      <td>44</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.186047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>P4_no_scaling</td>\n",
       "      <td>technical, sentiment, macro</td>\n",
       "      <td>naive_bayes</td>\n",
       "      <td>2572</td>\n",
       "      <td>644</td>\n",
       "      <td>44</td>\n",
       "      <td>0.498447</td>\n",
       "      <td>0.524300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>P4_no_scaling</td>\n",
       "      <td>technical, sentiment, macro</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>2572</td>\n",
       "      <td>644</td>\n",
       "      <td>44</td>\n",
       "      <td>0.515528</td>\n",
       "      <td>0.438849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>P4_no_scaling</td>\n",
       "      <td>technical, sentiment, macro</td>\n",
       "      <td>svm</td>\n",
       "      <td>2572</td>\n",
       "      <td>644</td>\n",
       "      <td>44</td>\n",
       "      <td>0.559006</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>P5_short_windows_returns</td>\n",
       "      <td>technical, sentiment, macro</td>\n",
       "      <td>decision_tree</td>\n",
       "      <td>2572</td>\n",
       "      <td>644</td>\n",
       "      <td>47</td>\n",
       "      <td>0.517081</td>\n",
       "      <td>0.439640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>P5_short_windows_returns</td>\n",
       "      <td>technical, sentiment, macro</td>\n",
       "      <td>gradient_boosting</td>\n",
       "      <td>2572</td>\n",
       "      <td>644</td>\n",
       "      <td>47</td>\n",
       "      <td>0.538820</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>P5_short_windows_returns</td>\n",
       "      <td>technical, sentiment, macro</td>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>2572</td>\n",
       "      <td>644</td>\n",
       "      <td>47</td>\n",
       "      <td>0.559006</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>P5_short_windows_returns</td>\n",
       "      <td>technical, sentiment, macro</td>\n",
       "      <td>naive_bayes</td>\n",
       "      <td>2572</td>\n",
       "      <td>644</td>\n",
       "      <td>47</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.435897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>P5_short_windows_returns</td>\n",
       "      <td>technical, sentiment, macro</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>2572</td>\n",
       "      <td>644</td>\n",
       "      <td>47</td>\n",
       "      <td>0.549689</td>\n",
       "      <td>0.104938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>P5_short_windows_returns</td>\n",
       "      <td>technical, sentiment, macro</td>\n",
       "      <td>svm</td>\n",
       "      <td>2572</td>\n",
       "      <td>644</td>\n",
       "      <td>47</td>\n",
       "      <td>0.559006</td>\n",
       "      <td>0.006993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                preproc_profile                 feature_sets  \\\n",
       "0                   P0_baseline  technical, sentiment, macro   \n",
       "1                   P0_baseline  technical, sentiment, macro   \n",
       "2                   P0_baseline  technical, sentiment, macro   \n",
       "3                   P0_baseline  technical, sentiment, macro   \n",
       "4                   P0_baseline  technical, sentiment, macro   \n",
       "5                   P0_baseline  technical, sentiment, macro   \n",
       "6   P1_median_mode_no_indicator  technical, sentiment, macro   \n",
       "7   P1_median_mode_no_indicator  technical, sentiment, macro   \n",
       "8   P1_median_mode_no_indicator  technical, sentiment, macro   \n",
       "9   P1_median_mode_no_indicator  technical, sentiment, macro   \n",
       "10  P1_median_mode_no_indicator  technical, sentiment, macro   \n",
       "11  P1_median_mode_no_indicator  technical, sentiment, macro   \n",
       "12   P2_robust_scaler_winsorize  technical, sentiment, macro   \n",
       "13   P2_robust_scaler_winsorize  technical, sentiment, macro   \n",
       "14   P2_robust_scaler_winsorize  technical, sentiment, macro   \n",
       "15   P2_robust_scaler_winsorize  technical, sentiment, macro   \n",
       "16   P2_robust_scaler_winsorize  technical, sentiment, macro   \n",
       "17   P2_robust_scaler_winsorize  technical, sentiment, macro   \n",
       "18             P3_minmax_global  technical, sentiment, macro   \n",
       "19             P3_minmax_global  technical, sentiment, macro   \n",
       "20             P3_minmax_global  technical, sentiment, macro   \n",
       "21             P3_minmax_global  technical, sentiment, macro   \n",
       "22             P3_minmax_global  technical, sentiment, macro   \n",
       "23             P3_minmax_global  technical, sentiment, macro   \n",
       "24                P4_no_scaling  technical, sentiment, macro   \n",
       "25                P4_no_scaling  technical, sentiment, macro   \n",
       "26                P4_no_scaling  technical, sentiment, macro   \n",
       "27                P4_no_scaling  technical, sentiment, macro   \n",
       "28                P4_no_scaling  technical, sentiment, macro   \n",
       "29                P4_no_scaling  technical, sentiment, macro   \n",
       "30     P5_short_windows_returns  technical, sentiment, macro   \n",
       "31     P5_short_windows_returns  technical, sentiment, macro   \n",
       "32     P5_short_windows_returns  technical, sentiment, macro   \n",
       "33     P5_short_windows_returns  technical, sentiment, macro   \n",
       "34     P5_short_windows_returns  technical, sentiment, macro   \n",
       "35     P5_short_windows_returns  technical, sentiment, macro   \n",
       "\n",
       "                  model  train_samples  test_samples  num_features  accuracy  \\\n",
       "0         decision_tree           2572           644            44  0.557453   \n",
       "1     gradient_boosting           2572           644            44  0.531056   \n",
       "2   logistic_regression           2572           644            44  0.559006   \n",
       "3           naive_bayes           2572           644            44  0.526398   \n",
       "4         random_forest           2572           644            44  0.555901   \n",
       "5                   svm           2572           644            44  0.559006   \n",
       "6         decision_tree           2572           644            36  0.543478   \n",
       "7     gradient_boosting           2572           644            36  0.501553   \n",
       "8   logistic_regression           2572           644            36  0.559006   \n",
       "9           naive_bayes           2572           644            36  0.526398   \n",
       "10        random_forest           2572           644            36  0.568323   \n",
       "11                  svm           2572           644            36  0.559006   \n",
       "12        decision_tree           2572           644            44  0.543478   \n",
       "13    gradient_boosting           2572           644            44  0.552795   \n",
       "14  logistic_regression           2572           644            44  0.559006   \n",
       "15          naive_bayes           2572           644            44  0.526398   \n",
       "16        random_forest           2572           644            44  0.548137   \n",
       "17                  svm           2572           644            44  0.559006   \n",
       "18        decision_tree           2572           644            44  0.515528   \n",
       "19    gradient_boosting           2572           644            44  0.531056   \n",
       "20  logistic_regression           2572           644            44  0.559006   \n",
       "21          naive_bayes           2572           644            44  0.526398   \n",
       "22        random_forest           2572           644            44  0.515528   \n",
       "23                  svm           2572           644            44  0.559006   \n",
       "24        decision_tree           2572           644            44  0.503106   \n",
       "25    gradient_boosting           2572           644            44  0.531056   \n",
       "26  logistic_regression           2572           644            44  0.565217   \n",
       "27          naive_bayes           2572           644            44  0.498447   \n",
       "28        random_forest           2572           644            44  0.515528   \n",
       "29                  svm           2572           644            44  0.559006   \n",
       "30        decision_tree           2572           644            47  0.517081   \n",
       "31    gradient_boosting           2572           644            47  0.538820   \n",
       "32  logistic_regression           2572           644            47  0.559006   \n",
       "33          naive_bayes           2572           644            47  0.521739   \n",
       "34        random_forest           2572           644            47  0.549689   \n",
       "35                  svm           2572           644            47  0.559006   \n",
       "\n",
       "          f1  \n",
       "0   0.435644  \n",
       "1   0.452899  \n",
       "2   0.000000  \n",
       "3   0.442413  \n",
       "4   0.052980  \n",
       "5   0.006993  \n",
       "6   0.423529  \n",
       "7   0.499220  \n",
       "8   0.000000  \n",
       "9   0.442413  \n",
       "10  0.125786  \n",
       "11  0.006993  \n",
       "12  0.425781  \n",
       "13  0.186441  \n",
       "14  0.000000  \n",
       "15  0.442413  \n",
       "16  0.120846  \n",
       "17  0.006993  \n",
       "18  0.417910  \n",
       "19  0.365546  \n",
       "20  0.000000  \n",
       "21  0.442413  \n",
       "22  0.395349  \n",
       "23  0.006993  \n",
       "24  0.416058  \n",
       "25  0.398406  \n",
       "26  0.186047  \n",
       "27  0.524300  \n",
       "28  0.438849  \n",
       "29  0.000000  \n",
       "30  0.439640  \n",
       "31  0.400000  \n",
       "32  0.000000  \n",
       "33  0.435897  \n",
       "34  0.104938  \n",
       "35  0.006993  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df = load_dataset()\n",
    "ablation_results = run_ablation(raw_df)\n",
    "\n",
    "sort_columns = [column for column in [\"preproc_profile\", \"feature_sets\", \"model\"] if column in ablation_results.columns]\n",
    "if sort_columns:\n",
    "    ablation_results = ablation_results.sort_values(by=sort_columns)\n",
    "\n",
    "ablation_results.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e175b92",
   "metadata": {},
   "source": [
    "## Notes\n",
    "- All preprocessing and model definitions are sourced from `assets/config.json`.\n",
    "- Extend the experiment by editing the configuration (e.g., add feature sets or models) and re-running the notebook.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
